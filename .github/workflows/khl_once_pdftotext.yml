name: khl_once_pdftotext

on:
  workflow_dispatch: {}

permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  run:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    env:
      UID: "897694"
      SEASON: "1369"
      OUT_DIR: "public/khl/json"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: MARKER — USING PDFTOTEXT (not fitz)
        run: echo "USING PDFTOTEXT WORKFLOW ✅"

      - name: Install poppler-utils (pdftotext)
        run: |
          sudo apt-get update -y
          sudo apt-get install -y poppler-utils

      - name: Fetch PDF
        run: |
          set -e
          mkdir -p "$OUT_DIR"
          PDF_URL="https://khl.ru/pdf/${{ env.SEASON }}/${{ env.UID }}/game-${{ env.UID }}-start-ru.pdf"
          UA="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
          curl -sSL --http2 --fail \
            -H "Accept: application/pdf,application/octet-stream;q=0.9,*/*;q=0.8" \
            -H "Accept-Language: ru,en;q=0.9" \
            -H "Referer: https://khl.ru/" \
            -H "User-Agent: $UA" \
            -o /tmp/game.pdf "$PDF_URL"

      - name: pdftotext -layout
        run: |
          pdftotext -layout -nopgbrk /tmp/game.pdf /tmp/game.txt
          echo "Dump HEAD/TAIL from pdftotext:"
          python - <<'PY'
          import re, pathlib
          raw = pathlib.Path("/tmp/game.txt").read_text(encoding="utf-8", errors="ignore")
          lines = [re.sub(r"[ \t]+"," ", x).rstrip() for x in raw.splitlines() if x.strip()]
          print("\n===== HEAD 40 =====")
          for i,l in enumerate(lines[:40],1): print(f"{i:03d}: {l}")
          print("\n===== TAIL 80 =====")
          for i,l in enumerate(lines[-80:], max(1,len(lines)-79)): print(f"{i:03d}: {l}")
          PY

      - name: Parse → JSON (teams / time / date / referees / goalies)
        run: |
        echo "PARSER_MARK: V2D"

          python - <<'PY'
          import os, re, json, pathlib, unicodedata
from datetime import datetime

UID = int(os.environ["UID"])
OUT_DIR = os.environ["OUT_DIR"]

raw = pathlib.Path("/tmp/game.txt").read_text(encoding="utf-8", errors="ignore")

def strip_accents(s: str) -> str:
    return "".join(ch for ch in unicodedata.normalize("NFD", s) if unicodedata.category(ch) != "Mn")

def norm_keep(s: str) -> str:
    s = unicodedata.normalize("NFKC", s)
    s = s.replace("\xa0"," ").replace("\u2009"," ").replace("\u202f"," ")
    return s.rstrip()

lines = [norm_keep(x) for x in raw.splitlines() if x.strip()]
lines_noacc = [strip_accents(x) for x in lines]
full  = "\n".join(x.strip() for x in lines_noacc)

# --- TEAMS (оставим пока None; это отдельный хелпер под макет) ---
teams = [None, None]

# --- TIME ---
m_time = re.search(r"Начало\s*матча\s*:\s*(\d{2}:\d{2})", full)
time_msk = m_time.group(1) if m_time else None

# --- DATE ---
m_upd = re.search(r"Обновлено:\s*(\d{2}[./-]\d{2}[./-]\d{4})", full)
if m_upd:
    date = m_upd.group(1).replace("/", ".").replace("-", ".")
else:
    all_dates = re.findall(r"\b(\d{2}[./-]\d{2}[./-]\d{4})\b", full)
    def to_dt(s):
        s = s.replace("/", ".").replace("-", ".")
        try: return datetime.strptime(s, "%d.%m.%Y")
        except: return None
    cands = [to_dt(d) for d in all_dates]
    cands = [d for d in cands if d and 2024 <= d.year <= 2030]
    date = max(cands).strftime("%d.%m.%Y") if cands else None

# --- REFEREES ---
main_referees, linesmen = [], []
idx_role = None
for i, l in enumerate(lines_noacc):
    if "Главный судья" in l and "Линейный судья" in l:
        idx_role = i
        break
if idx_role is not None and idx_role + 1 < len(lines_noacc):
    fio_line = " ".join(lines_noacc[idx_role+1: idx_role+3]).strip()
    # Разбиваем на ФИО попарно по словам (Фамилия Имя) — в твоём логе: "Гофман Антон Лазарев Глеб Егоров Сергей Сивов Дмитрий"
    toks = [t for t in fio_line.split() if t]
    pairs = [" ".join(toks[i:i+2]) for i in range(0, min(len(toks), 8), 2)]
    main_referees = pairs[:2]
    linesmen      = pairs[2:4] if len(pairs) >= 4 else []

# --- GOALIES ---
goal_home, goal_away = []

# Найдём индекс шапки "Вратари Вратари"
idx_g = None
for i, l in enumerate(lines_noacc):
    if re.search(r"\bВратари\b\s+\bВратари\b", l):
        idx_g = i
        break

def parse_goalie_segments(line: str):
    """
    В строке типа:
    '70 В Николаев Дмитрий Н. С 25.01.2000 25  44 В Щетилин Алексей С 28.11.2000 24'
    достаём два блока (левый и правый).
    """
    s = line
    # два вхождения шаблона: номер + 'В' + имя ... + (С|Р) дата
    pat = re.compile(
        r'(?P<num>\d{1,2})\s+В\s+'
        r'(?P<name>[А-ЯЁ][а-яё\-\.]+(?:\s[А-ЯЁ][а-яё\-\.]+){1,3})'
        r'(?:\s+[СР])?\s+\d{2}\.\d{2}\.\d{4}'
    )
    matches = list(pat.finditer(s))
    out = []
    for m in matches[:2]:
        name = m.group("name")
        # статус ищем отдельно (буква С/Р перед датой)
        after = s[m.end()-10 : m.end()+20]  # небольшой контекст вокруг даты
        mstat = re.search(r'\b([СР])\s*\d{2}\.\d{2}\.\d{4}', s[m.start():m.end()+20])
        status = {"С":"starter","Р":"reserve"}.get(mstat.group(1), "") if mstat else ""
        # подчистим финальный инициал вида "Н." на конце имени
        name = re.sub(r'\s+[А-ЯЁ]\.$', '', name).strip()
        out.append({"name": name, "gk_status": status})
    return out

if idx_g is not None:
    # Возьмём 3 строки после заголовка "Вратари Вратари" (как в твоём TAIL)
    for row in lines_noacc[idx_g+1 : min(idx_g+4, len(lines_noacc))]:
        segs = parse_goalie_segments(row)
        if len(segs) == 2:
            if not goal_home: goal_home = []
            if not goal_away: goal_away = []
            goal_home.append(segs[0])
            goal_away.append(segs[1])

out = {
  "ok": True,
  "uid": UID,
  "data": {
    "teams": teams,
    "date": date,
    "time_msk": time_msk,
    "main_referees": main_referees,
    "linesmen": linesmen,
    "goalies": { "home": goal_home, "away": goal_away }
  }
}
p = pathlib.Path(OUT_DIR) / f"{UID}.json"
p.parent.mkdir(parents=True, exist_ok=True)
p.write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")
print("Wrote", p)

          PY

      - name: Upload artifact (public)
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
