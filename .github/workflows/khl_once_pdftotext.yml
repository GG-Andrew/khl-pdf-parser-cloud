name: KHL PDF → JSON (pdftotext)

on:
  workflow_dispatch:
    inputs:
      uid:
        description: "KHL match UID"
        required: true
        default: "897694"
      season:
        description: "Season code"
        required: true
        default: "1369"

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

env:
  UID: ${{ github.event.inputs.uid }}
  SEASON: ${{ github.event.inputs.season }}
  OUT_DIR: public/khl/json

jobs:
  run:
    environment:
      name: github-pages
      url: ${{ steps.deploy.outputs.page_url }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: MARKER — USING PDFTOTEXT (not fitz)
        run: echo "PARSER_MARK: v2D (pdftotext)"

      - name: Install poppler-utils (pdftotext)
        run: sudo apt-get update && sudo apt-get install -y poppler-utils

      - name: Fetch PDF
        run: |
          set -e
          mkdir -p "$OUT_DIR"
          PDF_URL="https://khl.ru/pdf/${SEASON}/${UID}/game-${UID}-start-ru.pdf"
          UA="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
          echo "GET $PDF_URL"
          curl -sSL --http2 --fail \
            -H "Accept: application/pdf,application/octet-stream;q=0.9,*/*;q=0.8" \
            -H "Accept-Language: ru,en;q=0.9" \
            -H "Referer: https://khl.ru/" \
            -H "User-Agent: $UA" \
            -o /tmp/game.pdf "$PDF_URL"

      - name: pdftotext -layout
        run: |
          set -e
          pdftotext -layout -nopgbrk /tmp/game.pdf /tmp/game.txt
          echo "Dump HEAD/TAIL from pdftotext:"
          python - <<'PY'
          import re, pathlib
          raw = pathlib.Path("/tmp/game.txt").read_text(encoding="utf-8", errors="ignore")
          lines = [re.sub(r"[ \t]+"," ", x).rstrip() for x in raw.splitlines() if x.strip()]
          print("\n===== HEAD 40 =====")
          for i,l in enumerate(lines[:40],1): print(f"{i:03d}: {l}")
          print("\n===== TAIL 80 =====")
          for i,l in enumerate(lines[-80:],1): print(f"{i:03d}: {l}")
          PY

      - name: Parse → JSON (teams / time / date / referees / goalies)
        run: |
          python - <<'PY'
          import os, re, json, pathlib, unicodedata
          from datetime import datetime

          UID = int(os.environ["UID"])
          PUBLIC  = pathlib.Path("public")
          RAW_DIR = PUBLIC / "khl" / "raw"
          JSON_DIR= PUBLIC / "khl" / "json"
          RAW_DIR.mkdir(parents=True, exist_ok=True)
          JSON_DIR.mkdir(parents=True, exist_ok=True)

          raw = pathlib.Path("/tmp/game.txt").read_text(encoding="utf-8", errors="ignore")
          (RAW_DIR / f"{UID}_game.txt").write_text(raw, encoding="utf-8")

          def strip_marks(s:str)->str:
              s = unicodedata.normalize("NFKD", s)
              s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
              s = s.replace("\xa0"," ").replace("\u2009"," ").replace("\u202f"," ")
              return s
          def norm_line(s:str)->str:
              s = strip_marks(s)
              s = re.sub(r"[ \t]+"," ", s)
              return s.strip()

          lines = [norm_line(x) for x in raw.splitlines() if x.strip()]
          full  = "\n".join(lines)
          (RAW_DIR / f"{UID}_lines.json").write_text(json.dumps(lines, ensure_ascii=False, indent=2), encoding="utf-8")

          # ---------- TEAMS ----------
          KHL_TEAMS = [
              "АК БАРС","АВАНГАРД","АВТОМОБИЛИСТ","АМУР","БАРЫС","ВИТЯЗЬ","ДИНАМО М","ДИНАМО МИНСК",
              "ЛОКОМОТИВ","МЕТАЛЛУРГ МГ","НЕФТЕХИМИК","САЛАВАТ ЮЛАЕВ","СЕВЕРСТАЛЬ","СИБИРЬ",
              "СКА","СОЧИ","ХК СОЧИ","СПАРТАК МОСКВА","ТРАКТОР","ТОРПЕДО","ЦСКА","ЙОКЕРИТ","КУНЬЛУНЬ"
          ]
          def find_teams():
              idx = None
              for i,ln in enumerate(lines[:25]):
                  if "№ Поз Фамилия" in ln:
                      idx = max(0, i-1); break
              if idx is None:
                  for i,ln in enumerate(lines[:40]):
                      if any(t in ln.upper() for t in KHL_TEAMS):
                          idx = i; break
              if idx is None: return [None,None]
              txt = lines[idx].upper()
              hits = []
              for t in KHL_TEAMS:
                  if t in txt: hits.append(t)
              uniq = []
              for h in hits:
                  if h not in uniq: uniq.append(h)
              # убрать короткие дубли
              cleaned = []
              for h in uniq:
                  if any(h != x and h in x for x in uniq): continue
                  cleaned.append(h)
              uniq = cleaned or uniq
              if len(uniq) >= 2:
                  return [uniq[0].title(), uniq[1].title()]
              return [None,None]
          teams = find_teams()

          # ---------- TIME ----------
          m_time = re.search(r"Начало\s+матча:\s*(\d{2}:\d{2})", full)
          time_msk = m_time.group(1) if m_time else None

          # ---------- DATE ----------
          m_upd = re.search(r"Обновлено:\s*(\d{2}[./-]\d{2}[./-]\d{4})", full)
          if m_upd:
              date = m_upd.group(1).replace("/",".").replace("-",".")
          else:
              all_dates = re.findall(r"\b(\d{2}[./-]\d{2}[./-]\d{4})\b", full)
              def to_dt(s):
                  s = s.replace("/",".").replace("-",".")
                  try: return datetime.strptime(s, "%d.%m.%Y")
                  except: return None
              cands = [to_dt(d) for d in all_dates]
              cands = [d for d in cands if d and 2024 <= d.year <= 2030]
              date = max(cands).strftime("%d.%m.%Y") if cands else None

          # ---------- REFEREES ----------
          STOPWORDS = {"СОСТАВЫ","КОМАНД","ЗВЕНО","ВРАТАРИ","ГЛАВНЫЙ","СУДЬЯ","ЛИНЕЙНЫЙ","ОБНОВЛЕНО","МАТЧ","НАЧАЛО","MSK","ДС"}
          def is_name(tok: str) -> bool:
              up = tok.upper()
              if any(sw in up for sw in STOPWORDS): return False
              return bool(re.fullmatch(r"[А-ЯЁ][а-яё]+(?:\s+[А-ЯЁ][а-яё]+){1,2}", tok))

          main_referees, linesmen = [], []
          for i,ln in enumerate(lines[:160]):
              if "ГЛАВНЫЙ СУДЬЯ" in ln.upper():
                  window = " ".join(lines[i:i+4])
                  cands = re.findall(r"[А-ЯЁ][а-яё]+(?:\s+[А-ЯЁ][а-яё]+){1,2}", window)
                  cands = [x for x in cands if is_name(x)]
                  main_referees = cands[:2]
                  linesmen     = cands[2:4]
                  break

          # ---------- GOALIES ----------
          goal = {"home": [], "away": []}
          def parse_goalie_side(side_txt: str):
              m = re.search(r"\b(\d{1,2})\s+В\s+([А-ЯЁ][а-яё]+)\s+([А-ЯЁ][а-яё]+)(?:\s+[А-ЯЁ]\.)?\s+([СР])\b", side_txt)
              if not m: return None
              num, last, first, stat = m.groups()
              return {"number": int(num), "name": f"{last} {first}", "status": "starter" if stat == "С" else "reserve"}

          try:
              idx = next(i for i,ln in enumerate(lines[:60]) if re.search(r"\bВратари\s+Вратари\b", ln, re.I))
              for row in lines[idx+1: idx+5]:
                  parts = re.split(r"\s{2,}", row)
                  if len(parts) < 2: continue
                  L, R = parts[0], parts[-1]
                  l = parse_goalie_side(L)
                  r = parse_goalie_side(R)
                  if l: goal["home"].append(l)
                  if r: goal["away"].append(r)
          except StopIteration:
              pass

          out = {
              "ok": True,
              "uid": UID,
              "data": {
                  "teams": teams,
                  "date": date,
                  "time_msk": time_msk,
                  "main_referees": main_referees,
                  "linesmen": linesmen,
                  "goalies": goal
              }
          }
          (JSON_DIR / f"{UID}.json").write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")
          print("Wrote", (JSON_DIR / f"{UID}.json"))
          PY

      # === ВАЖНО: грузим весь каталог public, а не только json! ===
      - name: Upload artifact (public)
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

      - name: Deploy to GitHub Pages
        id: deploy
        uses: actions/deploy-pages@v4
