name: KHL PDF → JSON (pdftotext)

on:
  workflow_dispatch:
    inputs:
      uid:
        description: "KHL match UID"
        required: true
        default: "897694"
      season:
        description: "KHL season code"
        required: true
        default: "1369"

permissions:
  contents: read
  pages: write
  id-token: write

env:
  UID: ${{ inputs.uid }}
  SEASON: ${{ inputs.season }}
  OUT_DIR: public/khl/json

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install poppler-utils (pdftotext)
        run: |
          sudo apt-get update
          sudo apt-get install -y poppler-utils

      - name: Fetch PDF
        shell: bash
        run: |
          set -e
          mkdir -p /tmp
          UA="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
          PDF_URL="https://khl.ru/pdf/${SEASON}/${UID}/game-${UID}-start-ru.pdf"
          echo "[INFO] GET ${PDF_URL}"
          curl -sSL --http2 --fail \
            -H "Accept: application/pdf,application/octet-stream;q=0.9,*/*;q=0.8" \
            -H "Accept-Language: ru,en;q=0.9" \
            -H "Referer: https://khl.ru/" \
            -H "User-Agent: ${UA}" \
            -o /tmp/game.pdf "${PDF_URL}"
          ls -l /tmp/game.pdf

      - name: pdftotext -layout
        shell: bash
        run: |
          set -e
          pdftotext -layout -nopgbrk /tmp/game.pdf /tmp/game.txt
          echo "===== HEAD 40 ====="
          head -n 40 /tmp/game.txt | nl -ba
          echo "===== TAIL 80 ====="
          tail -n 80 /tmp/game.txt | nl -ba

      - name: Parse → JSON (teams / date / time / referees / goalies)
        shell: bash
        run: |
          set -e
          mkdir -p "$OUT_DIR"
          mkdir -p public/khl/raw

          python - <<'PY'
          import os, re, json, pathlib
from datetime import datetime

UID = int(os.environ["UID"])
OUT_DIR = os.environ["OUT_DIR"]
PUBLIC = pathlib.Path("public")
RAW_DIR = PUBLIC / "khl" / "raw"
JSON_DIR = PUBLIC / "khl" / "json"

RAW_DIR.mkdir(parents=True, exist_ok=True)
JSON_DIR.mkdir(parents=True, exist_ok=True)

raw = pathlib.Path("/tmp/game.txt").read_text(encoding="utf-8", errors="ignore")

# Сохраним сырой txt для отладки (чтобы не было 404)
(pathlib.Path(RAW_DIR) / f"{UID}_game.txt").write_text(raw, encoding="utf-8")

# Нормализация
def strip_accents(s:str)->str:
    return (s
            .replace("\xa0"," ")
            .replace("\u2009"," ")
            .replace("\u202f"," ")
            )

def norm_line(s:str)->str:
    s = strip_accents(s)
    s = re.sub(r"[ \t]+"," ", s)
    return s.strip()

lines = [norm_line(x) for x in raw.splitlines() if x.strip()]
full  = "\n".join(lines)

# -------- TEAMS --------
# Словарь допустимых названий (простого вида достаточно)
KHL_TEAMS = [
    "АК БАРС", "АВАНГАРД", "АВТОМОБИЛИСТ", "АМУР", "АВТОМОБИЛИСТ ЕКАТЕРИНБУРГ",
    "БАРЫС", "ВИТЯЗЬ", "ДИНАМО М", "ДИНАМО МИНСК", "ДИНАМО РИГА", "ЙОКЕРИТ",
    "КУНЬЛУНЬ", "ЛОКОМОТИВ", "МЕТАЛЛУРГ МГ", "НЕФТЕХИМИК", "САЛАВАТ ЮЛАЕВ",
    "СЕВЕРСТАЛЬ", "СИБИРЬ", "СКА", "СОЧИ", "СПАРТАК МОСКВА", "ТРАКТОР", "ТОРПЕДО", "ЦСКА", "ХК СОЧИ"
]

def find_teams(lines):
    # ищем строку с названием двух команд без разделителей, как в примере
    # возьмём строку около заголовка "№ Поз Фамилия, Имя"
    cand_idx = None
    for i,ln in enumerate(lines[:20]):
        if "№ Поз Фамилия" in ln:
            cand_idx = max(0, i-1)
            break
    if cand_idx is None:
        # бэкап: ищем строку, где встречается хотя бы одно известное имя команды
        for i,ln in enumerate(lines[:40]):
            if sum(1 for t in KHL_TEAMS if t in ln.upper()) >= 1:
                cand_idx = i
                break

    if cand_idx is None:
        return [None, None]

    txt = lines[cand_idx].upper()
    # выделим все встречающиеся токены из словаря
    hits = []
    for t in KHL_TEAMS:
        if t in txt:
            hits.append(t)
    # оставим уникальные и разумное количество (2)
    uniq = []
    for h in hits:
        if h not in uniq:
            uniq.append(h)
    if len(uniq) >= 2:
        # частые дубли вида "ХК СОЧИ" + "СОЧИ" — уберём короткий дубль
        cleaned = []
        for h in uniq:
            if any(h != x and h in x for x in uniq):
                continue
            cleaned.append(h)
        uniq = cleaned or uniq
        return [uniq[0].title(), uniq[1].title()]
    return [None, None]

teams = find_teams(lines)

# -------- TIME --------
m_time = re.search(r"Начало\s+матча:\s*(\d{2}:\d{2})", full)
time_msk = m_time.group(1) if m_time else None

# -------- DATE --------
m_upd = re.search(r"Обновлено:\s*(\d{2}[./-]\d{2}[./-]\d{4})", full)
if m_upd:
    date = m_upd.group(1).replace("/",".").replace("-",".")
else:
    all_dates = re.findall(r"\b(\d{2}[./-]\d{2}[./-]\d{4})\b", full)
    def to_dt(s):
        s = s.replace("/",".").replace("-",".")
        try: return datetime.strptime(s, "%d.%m.%Y")
        except: return None
    cands = [to_dt(d) for d in all_dates]
    cands = [d for d in cands if d]
    date = max(cands).strftime("%d.%m.%Y") if cands else None

# -------- REFEREES (главные / лайнсмены) --------
main_referees, linesmen = [], []
# Берём компактный блок судей: 3–4 строки вокруг фразы "Главный судья"
for i,ln in enumerate(lines[:150]):
    if "ГЛАВНЫЙ СУДЬЯ" in ln.upper():
        window = " ".join(lines[i:i+3])
        # Имена через пробелы:
        fio = re.findall(r"[А-ЯЁ][а-яё]+(?:\s+[А-ЯЁ][а-яё]+){1,2}", window)
        # первые 2 считаем главными, остальные лайнсменами
        main_referees = fio[:2]
        linesmen     = fio[2:4]
        break

# -------- GOALIES --------
# Берём 3 строки после "Вратари Вратари", разделяем на левую/правую колонку по >=2 пробелов
goal = {"home":[], "away":[]}
try:
    idx = next(i for i,ln in enumerate(lines[:50]) if re.search(r"\bВратари\s+Вратари\b", ln, re.I))
    goalie_block = lines[idx+1: idx+1+5]  # максимум 4–5 строк
    def parse_one(side_txt):
        # формат: "70 В Николаев Дмитрий ... С|Р"
        m = re.search(r"\b(\d{1,2})\s+В\s+([А-ЯЁ][а-яё]+)\s+([А-ЯЁ][а-яё]+).*?\b(С|Р)\b", side_txt)
        if not m: 
            return None
        num, last, first, stat = m.groups()
        return {
            "number": int(num),
            "name": f"{last} {first}",
            "status": {"С":"starter","Р":"reserve"}[stat]
        }
    for row in goalie_block:
        parts = re.split(r"\s{2,}", row)
        if len(parts) >= 2:
            left, right = parts[0], parts[-1]
            L = parse_one(left)
            R = parse_one(right)
            if L: goal["home"].append(L)
            if R: goal["away"].append(R)
except StopIteration:
    pass

# сохраним распиленные строки для отладки
(pathlib.Path(RAW_DIR) / f"{UID}_lines.json").write_text(
    json.dumps(lines, ensure_ascii=False, indent=2),
    encoding="utf-8"
)

out = {
    "ok": True,
    "uid": UID,
    "data": {
        "teams": teams,
        "date": date,
        "time_msk": time_msk,
        "main_referees": main_referees,
        "linesmen": linesmen,
        "goalies": goal
    }
}
(pathlib.Path(JSON_DIR) / f"{UID}.json").write_text(
    json.dumps(out, ensure_ascii=False, indent=2),
    encoding="utf-8"
)
print("Wrote", (JSON_DIR / f"{UID}.json"))

          PY

      - name: Show TREE of public
        shell: bash
        run: |
          echo "--- TREE public"
          find public -maxdepth 3 -type f -print | sort || true

      - name: Upload artifact (Pages)
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

      - name: Deploy to Pages
        id: deployment
        uses: actions/deploy-pages@v4
