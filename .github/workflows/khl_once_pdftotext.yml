name: khl_once_pdftotext

on:
  workflow_dispatch: {}

permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  run:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    env:
      UID: "897694"
      SEASON: "1369"
      OUT_DIR: "public/khl/json"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: MARKER — USING PDFTOTEXT (not fitz)
        run: echo "USING PDFTOTEXT WORKFLOW ✅"

      - name: Install poppler-utils (pdftotext)
        run: |
          sudo apt-get update -y
          sudo apt-get install -y poppler-utils

      - name: Fetch PDF
        run: |
          set -e
          mkdir -p "$OUT_DIR"
          PDF_URL="https://khl.ru/pdf/${{ env.SEASON }}/${{ env.UID }}/game-${{ env.UID }}-start-ru.pdf"
          UA="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
          curl -sSL --http2 --fail \
            -H "Accept: application/pdf,application/octet-stream;q=0.9,*/*;q=0.8" \
            -H "Accept-Language: ru,en;q=0.9" \
            -H "Referer: https://khl.ru/" \
            -H "User-Agent: $UA" \
            -o /tmp/game.pdf "$PDF_URL"

      - name: pdftotext -layout
        run: |
          pdftotext -layout -nopgbrk /tmp/game.pdf /tmp/game.txt
          echo "Dump HEAD/TAIL from pdftotext:"
          python - <<'PY'
          import re, pathlib
          raw = pathlib.Path("/tmp/game.txt").read_text(encoding="utf-8", errors="ignore")
          lines = [re.sub(r"[ \t]+"," ", x).rstrip() for x in raw.splitlines() if x.strip()]
          print("\n===== HEAD 40 =====")
          for i,l in enumerate(lines[:40],1): print(f"{i:03d}: {l}")
          print("\n===== TAIL 80 =====")
          for i,l in enumerate(lines[-80:], max(1,len(lines)-79)): print(f"{i:03d}: {l}")
          PY

      - name: Parse → JSON (teams / time / date / referees / goalies)
        run: |
        echo "PARSER_MARK: V2D"

          python - <<'PY'
          import os, re, json, unicodedata, pathlib
from datetime import datetime

UID = int(os.environ["UID"])
OUT_DIR = os.environ["OUT_DIR"]

raw = pathlib.Path("/tmp/game.txt").read_text(encoding="utf-8", errors="ignore")

def strip_accents(s: str) -> str:
    s = unicodedata.normalize("NFKD", s)
    return "".join(ch for ch in s if unicodedata.category(ch) != "Mn")

def norm_line(s: str) -> str:
    s = strip_accents(s)
    s = s.replace("\xa0"," ").replace("\u2009"," ").replace("\u202f"," ")
    s = re.sub(r"[ \t]+"," ", s)
    return s.strip()

lines = [norm_line(x) for x in raw.splitlines() if x.strip()]
full  = "\n".join(lines)

# --- Дата/время ---
m_date = re.search(r"(\d{2})[./-](\d{2})[./-](\d{4})", full)
date = f"{m_date.group(1)}.{m_date.group(2)}.{m_date.group(3)}" if m_date else None
m_time = re.search(r"(\d{2}:\d{2})\s*MSK", full, re.I)
time_msk = m_time.group(1) if m_time else None

# --- Команды (две колонки в шапке) ---
teams = [None, None]
for ln in lines[:20]:
    # шапка типа: СПАРТАК МОСКВА    ХК СОЧИ СОЧИ
    if re.search(r"[А-ЯA-Z]{2,}.*\s{2,}.*[А-ЯA-Z]{2,}", ln):
        parts = re.split(r"\s{2,}", ln)
        if len(parts) == 2 and all(len(p.strip()) >= 3 for p in parts):
            teams = [parts[0].strip(' "«»'), parts[1].strip(' "«»')]
            break

# --- Судьи (следующая строка после подписей) ---
main_refs, linesmen = [], []
for i, ln in enumerate(lines):
    if re.search(r"Главный судья.*Линейн\w+ судья", ln, re.I):
        # на следующей строке идут 4 фамилии+имени подряд
        if i + 1 < len(lines):
            names_line = lines[i+1]
            # разбиваем по двум и более пробелам
            chunks = [c.strip() for c in re.split(r"\s{2,}", names_line) if c.strip()]
            # если не сработало — fallback по одиночным пробелам, сгруппуем парами
            if len(chunks) < 4:
                words = names_line.split()
                chunks = [" ".join(words[j:j+2]) for j in range(0, min(len(words),8), 2)]
            if len(chunks) >= 4:
                main_refs = [chunks[0], chunks[1]]
                linesmen  = [chunks[2], chunks[3]]
        break

# --- Вратари ---
goal = {"home": [], "away": []}
# найдём маркер секции
idx = None
for i, ln in enumerate(lines):
    if re.search(r"\bВратари\b\s+\bВратари\b", ln, re.I):
        idx = i
        break

def parse_goal_row(text: str):
    """
    Парсит одну «ячейку» (левую или правую) с вратарём:
    '70 В Николаев Дмитрий С 25.01.2000 25' -> dict
    """
    # сначала вырежем конец с датой и возрастом
    text = re.sub(r"\s+\d{2}\.\d{2}\.\d{4}\s+\d{1,2}\s*$", "", text)
    # номер (в начале)
    m = re.match(r"^\s*(\d{1,2})\s+В\s+(.*)$", text)
    if not m:
        return None
    num = int(m.group(1))
    tail = m.group(2).strip()
    # признак старт/резерв встречается как отдельная буква С/Р
    status = ""
    if re.search(r"\bС\b", tail):
        status = "starter"
        tail = re.sub(r"\bС\b", "", tail)
    elif re.search(r"\bР\b", tail):
        status = "reserve"
        tail = re.sub(r"\bР\b", "", tail)
    # фамилия + имя (две первые “слова” после позиции)
    parts = tail.split()
    if len(parts) >= 2:
        name = f"{parts[0]} {parts[1]}"
    else:
        name = tail
    return {"number": num, "name": name, "status": status}

if idx is not None:
    # берём 1..3 строк после заголовка «Вратари Вратари»
    for row in lines[idx+1 : idx+4]:
        # делим строку на левую и правую «колонки» по ≥2 пробелам примерно пополам
        cols = re.split(r"\s{2,}", row)
        if len(cols) >= 2:
            left  = cols[0].strip()
            right = cols[-1].strip()
            L = parse_goal_row(left)
            R = parse_goal_row(right)
            if L: goal["home"].append(L)
            if R: goal["away"].append(R)

out = {
    "ok": True,
    "uid": UID,
    "data": {
        "teams": teams,
        "date": date,
        "time_msk": time_msk,
        "main_referees": main_refs,
        "linesmen": linesmen,
        "goalies": goal
    }
}

p = pathlib.Path(OUT_DIR) / f"{UID}.json"
p.parent.mkdir(parents=True, exist_ok=True)
p.write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")
print("Wrote", p)

          PY

      - name: Upload artifact (public)
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
